{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Random_Forest.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhl0GPHMQMOU"
      },
      "source": [
        "# Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Ihb-M7I2ooL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8554a364-8dd0-4ec8-8c44-6f06bf6753ff"
      },
      "source": [
        "!pip install -q wordcloud\n",
        "import wordcloud\n",
        "\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger') \n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "pd.set_option('display.max_columns',100)\n",
        "pd.set_option('display.max_rows',100)\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import re\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.probability import FreqDist\n",
        "from nltk.stem import PorterStemmer\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score, recall_score\n",
        "\n",
        "from sklearn import svm\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "from sklearn.dummy import DummyClassifier\n",
        "\n",
        "\n",
        "from wordcloud import WordCloud, STOPWORDS\n",
        "\n",
        "import string\n",
        "from matplotlib import style"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bksnaMog494X",
        "outputId": "9bed0d36-bc48-403f-9257-0fe1dc94be09"
      },
      "source": [
        "df = pd.read_csv('/content/clickbait_data.csv')\n",
        "df.info()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 32000 entries, 0 to 31999\n",
            "Data columns (total 2 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   headline   32000 non-null  object\n",
            " 1   clickbait  32000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 500.1+ KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LG2_5cn86Dda"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop = set(stopwords.words('english'))\n",
        "punctuation = list(string.punctuation)\n",
        "stop.update(punctuation)\n",
        "\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    final_text = []\n",
        "    for i in text.split():\n",
        "        if i.strip().lower() not in stop:\n",
        "            final_text.append(i.strip())\n",
        "    return \" \".join(final_text)\n",
        "\n",
        "df['headline']=df['headline'].apply(remove_stopwords)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "zudlh3oE8btt",
        "outputId": "fa1422d2-99d8-42be-ae5f-efa08efdefe6"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>clickbait</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Get Bings</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TV Female Friend Group Belong</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>New \"Star Wars: Force Awakens\" Trailer Give Ch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Vine New York \"Celebrity Big Brother\" Fucking ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Couple Stunning Photo Shoot Baby Learning Inop...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  clickbait\n",
              "0                                          Get Bings          1\n",
              "1                      TV Female Friend Group Belong          1\n",
              "2  New \"Star Wars: Force Awakens\" Trailer Give Ch...          1\n",
              "3  Vine New York \"Celebrity Big Brother\" Fucking ...          1\n",
              "4  Couple Stunning Photo Shoot Baby Learning Inop...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ALzAx__C8pkX",
        "outputId": "419b01cb-78e2-4495-e092-c33871c46b54"
      },
      "source": [
        "# converting to lowercase\n",
        "df['headline']=df['headline'].str.lower()\n",
        "df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>clickbait</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>get bings</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tv female friend group belong</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new \"star wars: force awakens\" trailer give ch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vine new york \"celebrity big brother\" fucking ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>couple stunning photo shoot baby learning inop...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  clickbait\n",
              "0                                          get bings          1\n",
              "1                      tv female friend group belong          1\n",
              "2  new \"star wars: force awakens\" trailer give ch...          1\n",
              "3  vine new york \"celebrity big brother\" fucking ...          1\n",
              "4  couple stunning photo shoot baby learning inop...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pmEM-JejBfsC"
      },
      "source": [
        "spec_chars = [\"-\",\"!\",'\"',\"#\",\"%\",\"&\",\"'\",\"(\",\")\",\n",
        "              \"*\",\"+\",\",\",\"-\",\".\",\"/\",\":\",\";\",\"<\",\n",
        "              \"=\",\">\",\"?\",\"@\",\"[\",\"\\\\\",\"]\",\"^\",\"_\",\n",
        "              \"`\",\"{\",\"|\",\"}\",\"~\",\"â€“\"]\n",
        "for char in spec_chars:\n",
        "    df['headline'] = df['headline'].str.replace(char, '')\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "auHBxUPzBotO",
        "outputId": "0bd6a178-9b8e-4aac-99aa-f103110b9a0e"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>headline</th>\n",
              "      <th>clickbait</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>get bings</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tv female friend group belong</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>new star wars force awakens trailer give chills</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>vine new york celebrity big brother fucking pe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>couple stunning photo shoot baby learning inop...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            headline  clickbait\n",
              "0                                          get bings          1\n",
              "1                      tv female friend group belong          1\n",
              "2    new star wars force awakens trailer give chills          1\n",
              "3  vine new york celebrity big brother fucking pe...          1\n",
              "4  couple stunning photo shoot baby learning inop...          1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wSCcCXYjB1NV"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = df['headline']\n",
        "y = df.clickbait\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.20, random_state=0)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AmRbpT_EFFpk"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vectorizer = TfidfVectorizer(stop_words='english', max_df=0.8, ngram_range=(1,2))\n",
        "tfidf_train_2 = tfidf_vectorizer.fit_transform(X_train)\n",
        "tfidf_test_2 = tfidf_vectorizer.transform(X_test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LpR6mq5MK-U5"
      },
      "source": [
        "import itertools\n",
        "import string\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer, HashingVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble.forest import RandomForestClassifier\n",
        "from sklearn import metrics\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    See full source and example: \n",
        "    http://scikit-learn.org/stable/auto_examples/model_selection/plot_confusion_matrix.html\n",
        "    \n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5sK1W61O_ZZ"
      },
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU_iQhiMJv3E",
        "outputId": "2ba878b9-e237-47b2-b9cc-e0eaf6c33998"
      },
      "source": [
        "rand_tf = RandomForestClassifier()\n",
        "rand_tf.fit(tfidf_train_2, y_train)\n",
        "pred = rand_tf.predict(tfidf_test_2)\n",
        "score = metrics.accuracy_score(y_test, pred)\n",
        "print(\"accuracy:   %0.3f\" % score)\n",
        "cm = metrics.confusion_matrix(y_test, pred, labels=[1, 0])\n",
        "print(cm)\n",
        "matrix = classification_report(y_test,pred,labels=[1,0])\n",
        "print('Classification report: \\n',matrix)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy:   0.921\n",
            "[[3006  190]\n",
            " [ 313 2891]]\n",
            "Classification report: \n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           1       0.91      0.94      0.92      3196\n",
            "           0       0.94      0.90      0.92      3204\n",
            "\n",
            "    accuracy                           0.92      6400\n",
            "   macro avg       0.92      0.92      0.92      6400\n",
            "weighted avg       0.92      0.92      0.92      6400\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNQ_qMCSNcNn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}